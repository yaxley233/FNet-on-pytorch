{"vocab_size": 32000, "hidden_size": 768, "embedding_size": 768, "intermediate_size": 3072, "max_position_embeddings": 512, "fourier": "fft", "pad_token_id": 3, "type_vocab_size": 4, "layer_norm_eps": 1e-12, "dropout_rate": 0.1, "num_hidden_layers": 12}
